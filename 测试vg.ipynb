{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from bert4keras.layers import Loss\n",
    "from bert4keras.optimizers import Adam\n",
    "from bert4keras.backend import keras, K\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.tokenizers import Tokenizer, load_vocab\n",
    "from bert4keras.snippets import sequence_padding, is_string\n",
    "from bert4keras.snippets import DataGenerator, AutoRegressiveDecoder\n",
    "\n",
    "from caption_eval.custom_caption_eval import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert配置\n",
    "config_path = 'bert-model/uncased_L-12_H-768_A-12/bert_config.json'\n",
    "checkpoint_path = 'bert-model/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "dict_path = 'bert-model/uncased_L-12_H-768_A-12/vocab.txt'\n",
    "\n",
    "# 加载并精简词表，建立分词器\n",
    "token_dict, keep_tokens = load_vocab(\n",
    "    dict_path=dict_path,\n",
    "    simplified=True,\n",
    "    startswith=['[PAD]', '[UNK]', '[CLS]', '[SEP]'],\n",
    ")\n",
    "tokenizer = Tokenizer(token_dict, do_lower_case=True)\n",
    "\n",
    "# 模型配置\n",
    "maxlen = 64\n",
    "batch_size = 16\n",
    "steps_per_epoch = 1000\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 81.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Read data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85283it [14:13, 99.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Train data numbers:  2992034\n",
      "-Train data steps per epoch 187002.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def read_object_data(folder, valid=False):\n",
    "    \"\"\"读取并整理COCO的数据,包括caption, object, attributes 和 relationships , 同时提取目标特征.\n",
    "    单个数据如下:\n",
    "    [\n",
    "     {'region_feature'：[2048], keywords': str, 'caption': str},\n",
    "     {'region_feature':[2048], keywords': str, 'caption': str},\n",
    "     ...\n",
    "    ]\n",
    "    \n",
    "    Returns:\n",
    "    -train:\n",
    "    [{'keywords': str,'region_feature': [2048],'caption': str},\n",
    "    ...\n",
    "    ]\n",
    "    \n",
    "    -valid:\n",
    "    [{'image_id':str,\n",
    "      'features': [2048],\n",
    "      'caption': [str, str, str, str, str],\n",
    "      'objects_key_words': [str, str, str, str, str]},\n",
    "    ...  \n",
    "    ]\n",
    "    \"\"\"\n",
    "    print('-Read data ...')\n",
    "    res = []\n",
    "    \n",
    "    files = os.listdir(folder)\n",
    "    \n",
    "    if valid:\n",
    "        # 读取image features 和 关键字\n",
    "        for _, file in tqdm(enumerate(files)):\n",
    "            file_path = folder + file\n",
    "            data = np.load(file_path, allow_pickle=True)\n",
    "        \n",
    "            image = {}\n",
    "            image_id = file.replace('npy', 'jpg')\n",
    "            image['image_id'] = image_id\n",
    "            image['regions']  = []\n",
    "\n",
    "            for region in data:\n",
    "                region['region_feature'] = np.array(region['region_feature'])\n",
    "                image['regions'].append(region)\n",
    "            \n",
    "            res.append(image)\n",
    "    else:\n",
    "        for _, file in tqdm(enumerate(files)):\n",
    "            file_path = folder + file\n",
    "            images = np.load(file_path, allow_pickle=True)\n",
    "        \n",
    "            for region in images:\n",
    "                region['region_feature'] = np.array(region['region_feature'])\n",
    "                res.append(region)\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "class data_generator(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        batch_features, batch_token_ids, batch_segment_ids = [], [], []\n",
    "        for is_end, D in self.sample(random):\n",
    "\n",
    "            features = D['region_feature']\n",
    "            caption = D['caption']\n",
    "            inputs = D['keywords']\n",
    "\n",
    "            token_ids, segment_ids = tokenizer.encode(\n",
    "                inputs, caption, max_length=maxlen\n",
    "            )\n",
    "            \n",
    "            batch_features.append(features)\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "                \n",
    "            if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                batch_features = np.array(batch_features)\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                yield [batch_token_ids, batch_segment_ids, batch_features], None\n",
    "                batch_features, batch_token_ids, batch_segment_ids = [], [], []\n",
    "\n",
    "# 加载数据\n",
    "train_data = read_object_data('./data/VisualGenome/train2016/', valid=False)\n",
    "#valid_data = read_object_data('./data/VisualGenome/valid2016/', valid=True)\n",
    "print('-Train data numbers: ', len(train_data))\n",
    "#print('-Valid data numbers: ', len(valid_data))\n",
    "print('-Train data steps per epoch', len(train_data)/16)\n",
    "#print('-Valid data steps per epoch', len(train_data)/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     multiple             22417920    Input-Token[0][0]                \n",
      "                                                                 MLM-Norm[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "image_features (InputLayer)     (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 768)    2099712     Embedding-Position[0][0]         \n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Attention-UniLM-Mask (Lambda)   (None, 1, None, None 0           Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2099712     Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 768)    2099712     Transformer-0-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2099712     Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 768)    2099712     Transformer-1-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2099712     Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 768)    2099712     Transformer-2-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2099712     Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 768)    2099712     Transformer-3-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    2099712     Transformer-4-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
      "                                                                 Transformer-4-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Norm  (None, None, 768)    2099712     Transformer-4-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    2099712     Transformer-5-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
      "                                                                 Transformer-5-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Norm  (None, None, 768)    2099712     Transformer-5-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    2099712     Transformer-6-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
      "                                                                 Transformer-6-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Norm  (None, None, 768)    2099712     Transformer-6-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    2099712     Transformer-7-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
      "                                                                 Transformer-7-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Norm  (None, None, 768)    2099712     Transformer-7-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    2099712     Transformer-8-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
      "                                                                 Transformer-8-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Norm  (None, None, 768)    2099712     Transformer-8-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    2099712     Transformer-9-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
      "                                                                 Transformer-9-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Norm  (None, None, 768)    2099712     Transformer-9-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    2099712     Transformer-10-MultiHeadSelfAtten\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
      "                                                                 Transformer-10-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Norm (None, None, 768)    2099712     Transformer-10-FeedForward-Add[0]\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    2099712     Transformer-11-MultiHeadSelfAtten\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
      "                                                                 Transformer-11-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Norm (None, None, 768)    2099712     Transformer-11-FeedForward-Add[0]\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, None, 768)    590592      Transformer-11-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, None, 768)    2099712     MLM-Dense[0][0]                  \n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Bias (BiasAdd)              (None, None, 29190)  29190       Embedding-Token[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Activation (Activation)     (None, None, 29190)  0           MLM-Bias[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cross_entropy_1 (CrossEntropy)  (None, None, 29190)  0           Input-Token[0][0]                \n",
      "                                                                 Input-Segment[0][0]              \n",
      "                                                                 MLM-Activation[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 163,042,566\n",
      "Trainable params: 163,042,566\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist/.local/lib/python3.6/site-packages/keras/engine/training_utils.py:819: UserWarning: Output cross_entropy_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to cross_entropy_1.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    }
   ],
   "source": [
    "class CrossEntropy(Loss):\n",
    "    \"\"\"交叉熵作为loss，并mask掉padding部分\n",
    "    \"\"\"\n",
    "    def compute_loss(self, inputs, mask=None):\n",
    "        y_true, y_mask, y_pred = inputs\n",
    "        y_true = y_true[:, 1:]  # 目标token_ids\n",
    "        y_mask = y_mask[:, 1:]  # segment_ids，刚好指示了要预测的部分\n",
    "        y_pred = y_pred[:, :-1]  # 预测序列，错开一位\n",
    "        loss = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "        loss = K.sum(loss * y_mask) / K.sum(y_mask)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "# 条件全连接层\n",
    "x_in = Input(shape=(2048,), name='image_features')\n",
    "    \n",
    "# Bert模型\n",
    "model = build_transformer_model(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    application='unilm',\n",
    "    keep_tokens=keep_tokens,  # 只保留keep_tokens中的字，精简原字表\n",
    "    layer_norm_cond=x_in,\n",
    "    layer_norm_cond_hidden_size=512,\n",
    "    layer_norm_cond_hidden_act='swish',\n",
    "    additional_input_layers=x_in,\n",
    ")\n",
    "\n",
    "\n",
    "output = CrossEntropy(2)(model.inputs[0:2] + model.outputs)\n",
    "\n",
    "model = Model(model.inputs, output)\n",
    "model.compile(optimizer=Adam(1e-5))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "class AutoCaption(AutoRegressiveDecoder):\n",
    "    \"\"\"img2seq解码器\n",
    "    \"\"\"\n",
    "    @AutoRegressiveDecoder.set_rtype('probas')\n",
    "    def predict(self, inputs, output_ids, step):\n",
    "        token_ids, segment_ids, image = inputs\n",
    "        token_ids = np.concatenate([token_ids, output_ids], 1)\n",
    "        segment_ids = np.concatenate([segment_ids, np.ones_like(output_ids)], 1)\n",
    "        return model.predict([token_ids, segment_ids, image])[:, -1]\n",
    "\n",
    "    def generate(self, inputs, features, topk=1):\n",
    "        token_ids, segment_ids = tokenizer.encode(inputs, max_length=maxlen)\n",
    "        output_ids = self.beam_search([token_ids, segment_ids, features], topk)  # 基于beam search\n",
    "        return tokenizer.decode(output_ids)\n",
    "\n",
    "\n",
    "autocaption = AutoCaption(\n",
    "    start_id=None,\n",
    "    end_id=tokenizer._token_end_id,\n",
    "    maxlen=maxlen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_show():\n",
    "    samples = [valid_data[i] for i in np.random.choice(len(valid_data), 2, replace=False)]\n",
    "    for img in samples:\n",
    "        region = np.random.choice(img['regions'])\n",
    "        print(u'image_id:', img['image_id'])\n",
    "        print(u'key_words:', region['keywords'])\n",
    "        print(u'predict:', autocaption.generate(region['keywords'], region['region_feature']))\n",
    "        print(u'references:', region['caption'])\n",
    "        print()\n",
    "        \n",
    "        \n",
    "def caption_eval(epoch, loss):\n",
    "    just_show()\n",
    "        \n",
    "    datasetGTS = {}\n",
    "    datasetRES = {}\n",
    "        \n",
    "    GTS_annotations = []\n",
    "    RES_annotations = []\n",
    "    \n",
    "    samples = [valid_data[i] for i in np.random.choice(len(valid_data), 5, replace=False)]\n",
    "    \n",
    "    imgId = 0\n",
    "    for _, sample in tqdm(enumerate(samples), desc='Reading data'):\n",
    "        for region in sample['regions']:\n",
    "            res = {}\n",
    "            res[u'image_id'] = imgId\n",
    "            res[u'caption'] = autocaption.generate(region['keywords'], region['region_feature'])\n",
    "            RES_annotations.append(res)\n",
    "            \n",
    "            gts = {}\n",
    "            gts[u'image_id'] = imgId\n",
    "            gts[u'caption'] = region['caption']\n",
    "            GTS_annotations.append(gts)\n",
    "            \n",
    "            imgId += 1\n",
    "            \n",
    "    imgIds = range(imgId)\n",
    "    datasetGTS['annotations'] = GTS_annotations\n",
    "    datasetRES['annotations'] = RES_annotations\n",
    "    \n",
    "    print(u'-Calculating scores ...')\n",
    "    scores = calculate_metrics(imgIds, datasetGTS, datasetRES)\n",
    "    print(scores)\n",
    "    \n",
    "    scores['epoch'] = epoch\n",
    "    scores['loss']  = loss\n",
    "    \n",
    "    save_path = 'models/VisualGenome/conditional_kw/'\n",
    "    \n",
    "    with open(save_path + 'caption_eval.txt', \"a\") as f:\n",
    "        f.write(str(scores) + '\\n')\n",
    "\n",
    "\n",
    "class Evaluate(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.lowest = 1e10\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # 保存模型\n",
    "        model.save_weights('models/VisualGenome/conditional_kw/model_{}.weights'.format(epoch))\n",
    "        \n",
    "#         scores = {}\n",
    "#         scores['epoch'] = epoch\n",
    "#         scores['loss']  = logs['loss']\n",
    "#         save_path = 'models/VisualGenome/conditional_kw/'\n",
    "    \n",
    "#         with open(save_path + 'caption_eval.txt', \"a\") as f:\n",
    "#             f.write(str(scores) + '\\n')\n",
    "        # 评价指标\n",
    "        caption_eval(epoch, logs['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluate()\n",
    "train_generator = data_generator(train_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 2.1179\n",
      "image_id: 2408745.jpg\n",
      "key_words: teddy bear bear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: the bear is wearing a bear\n",
      "references: a brown fluffy teddy bear\n",
      "\n",
      "image_id: 2401689.jpg\n",
      "key_words: woman pant \n",
      "predict: the woman is wearing black pants\n",
      "references: woman wearing black pants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data: 5it [00:18,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Calculating scores ...\n",
      "-tokenization...\n",
      "-setting up scorers...\n",
      "-computing Bleu score...\n",
      "{'testlen': 723, 'reflen': 743, 'guess': [723, 575, 427, 283], 'correct': [300, 74, 21, 5]}\n",
      "ratio: 0.9730820995949219\n",
      "Bleu_1: 0.404\n",
      "Bleu_2: 0.225\n",
      "Bleu_3: 0.134\n",
      "Bleu_4: 0.080\n",
      "-computing METEOR score...\n",
      "METEOR: 0.187\n",
      "-computing Rouge score...\n",
      "ROUGE_L: 0.387\n",
      "-computing CIDEr score...\n",
      "CIDEr: 1.409\n",
      "-computing SPICE score...\n",
      "-Prepare temp input file for the SPICE scorer.\n",
      "-Start job\n",
      "-Read and process results.\n",
      "-Average scores.\n",
      "-Scores.\n",
      "SPICE: 0.436\n",
      "-computing WMD score...\n",
      "WMD: 0.209\n",
      "{'Bleu_1': 0.40361684084720756, 'Bleu_2': 0.22478107176531206, 'Bleu_3': 0.13420408604315684, 'Bleu_4': 0.08028173999222438, 'METEOR': 0.1872992422163111, 'ROUGE_L': 0.3872265826337303, 'CIDEr': 1.4085632458342823, 'SPICE': 0.4362373737373737, 'WMD': 0.20920237286456608}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f20e1471a90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[evaluator]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
