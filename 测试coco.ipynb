{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from bert4keras.layers import Loss\n",
    "from bert4keras.optimizers import Adam\n",
    "from bert4keras.backend import keras, K\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.tokenizers import Tokenizer, load_vocab\n",
    "from bert4keras.snippets import sequence_padding, is_string\n",
    "from bert4keras.snippets import DataGenerator, AutoRegressiveDecoder\n",
    "\n",
    "from caption_eval.custom_caption_eval import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert配置\n",
    "config_path = 'bert-model/uncased_L-12_H-768_A-12/bert_config.json'\n",
    "checkpoint_path = 'bert-model/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "dict_path = 'bert-model/uncased_L-12_H-768_A-12/vocab.txt'\n",
    "\n",
    "# 加载并精简词表，建立分词器\n",
    "token_dict, keep_tokens = load_vocab(\n",
    "    dict_path=dict_path,\n",
    "    simplified=True,\n",
    "    startswith=['[PAD]', '[UNK]', '[CLS]', '[SEP]'],\n",
    ")\n",
    "tokenizer = Tokenizer(token_dict, do_lower_case=True)\n",
    "\n",
    "# 模型配置\n",
    "maxlen = 64\n",
    "batch_size = 16\n",
    "steps_per_epoch = 10\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77it [00:00, 766.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Read data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82396it [01:59, 692.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Read data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40263it [00:30, 1324.62it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_object_data(folder, valid=False):\n",
    "    \"\"\"读取并整理COCO的数据,包括caption, object, attributes 和 relationships , 同时提取目标特征.\n",
    "    单个数据如下:\n",
    "    [\n",
    "     {'image_features': [2048]},\n",
    "     {'key_words': str, 'caption': str},\n",
    "     {'key_words': str, 'caption': str},\n",
    "     ...\n",
    "    ]\n",
    "    \n",
    "    返回数据格式:\n",
    "    -train:\n",
    "    [{'key_words': str,\n",
    "      'features': [2048],\n",
    "      'caption': str},\n",
    "    ...\n",
    "    ]\n",
    "    \n",
    "    -valid:\n",
    "    [{'image_id':str,\n",
    "      'features': [2048],\n",
    "      'caption': [str, str, str, str, str],\n",
    "      'objects_key_words': [str, str, str, str, str]},\n",
    "    ...  \n",
    "    ]\n",
    "    \"\"\"\n",
    "    print('-Read data ...')\n",
    "    res = []\n",
    "    \n",
    "    files = os.listdir(folder)\n",
    "    \n",
    "    if valid:\n",
    "        # 读取valid的caption\n",
    "        data = json.load(open('data/coco2014/annotations/captions_val2014.json'))\n",
    "        images = {}\n",
    "        for img in data['images']:\n",
    "            images[img['id']] = {\n",
    "                'image_id': img['file_name'],\n",
    "                'caption': [],\n",
    "            }\n",
    "        for caption in data['annotations']:\n",
    "            images[caption['image_id']]['caption'].append(caption['caption'])\n",
    "        captions = {}\n",
    "        for img in images.values():\n",
    "            captions[img['image_id']] = img['caption']\n",
    "            \n",
    "        # 读取image features 和 关键字\n",
    "        for _, file in tqdm(enumerate(files)):\n",
    "            file_path = folder + file\n",
    "            data = np.load(file_path, allow_pickle=True)\n",
    "        \n",
    "            image = {}\n",
    "            image_id = file.replace('npy', 'jpg')\n",
    "            image['image_id'] = image_id\n",
    "            image['features'] = np.array(data[0]['image_features'])\n",
    "            image['caption']  = captions[image_id]\n",
    "            image['objects_key_words']  = []\n",
    "\n",
    "            for d in data[1:]:\n",
    "                image['objects_key_words'].append(d['key_words'])\n",
    "            \n",
    "            res.append(image)\n",
    "    else:\n",
    "        for _, file in tqdm(enumerate(files)):\n",
    "            file_path = folder + file\n",
    "            data = np.load(file_path, allow_pickle=True)\n",
    "        \n",
    "            for d in data[1:]:\n",
    "                d['features'] = np.array(data[0]['image_features'])\n",
    "            \n",
    "                res.append(d)\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "class data_generator(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        batch_features, batch_token_ids, batch_segment_ids = [], [], []\n",
    "        for is_end, D in self.sample(random):\n",
    "\n",
    "            features = D['features']\n",
    "            caption = D['caption']\n",
    "            inputs = D['key_words']\n",
    "\n",
    "            token_ids, segment_ids = tokenizer.encode(\n",
    "                inputs, caption, max_length=maxlen\n",
    "            )\n",
    "            \n",
    "            batch_features.append(features)\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "                \n",
    "            if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                batch_features = sequence_padding(batch_features)\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                yield [batch_token_ids, batch_segment_ids, batch_features], None\n",
    "                batch_features, batch_token_ids, batch_segment_ids = [], [], []\n",
    "\n",
    "                \n",
    "# 加载数据\n",
    "train_data = read_object_data(\n",
    "    './data/MSCOCO/annotation/features/train2014/', False\n",
    ")\n",
    "valid_data = read_object_data(\n",
    "    './data/MSCOCO/annotation/features/val2014/', True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(Loss):\n",
    "    \"\"\"交叉熵作为loss，并mask掉padding部分\n",
    "    \"\"\"\n",
    "    def compute_loss(self, inputs, mask=None):\n",
    "        y_true, y_mask, y_pred = inputs\n",
    "        y_true = y_true[:, 1:]  # 目标token_ids\n",
    "        y_mask = y_mask[:, 1:]  # segment_ids，刚好指示了要预测的部分\n",
    "        y_pred = y_pred[:, :-1]  # 预测序列，错开一位\n",
    "        loss = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "        loss = K.sum(loss * y_mask) / K.sum(y_mask)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# 条件全连接层\n",
    "x_in = Input(shape=(2048,), name='image_features')\n",
    "    \n",
    "# Bert模型\n",
    "model = build_transformer_model(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    application='unilm',\n",
    "    keep_tokens=keep_tokens,  # 只保留keep_tokens中的字，精简原字表\n",
    "    layer_norm_cond=x_in,\n",
    "    layer_norm_cond_hidden_size=512,\n",
    "    layer_norm_cond_hidden_act='swish',\n",
    "    additional_input_layers=x_in,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     multiple             22417920    Input-Token[0][0]                \n",
      "                                                                 MLM-Norm[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "image_features (InputLayer)     (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 768)    2098688     Embedding-Position[0][0]         \n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Attention-UniLM-Mask (Lambda)   (None, 1, None, None 0           Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2098688     Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 768)    2098688     Transformer-0-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2098688     Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 768)    2098688     Transformer-1-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2098688     Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 768)    2098688     Transformer-2-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2098688     Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 768)    2098688     Transformer-3-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    2098688     Transformer-4-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
      "                                                                 Transformer-4-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Norm  (None, None, 768)    2098688     Transformer-4-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    2098688     Transformer-5-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
      "                                                                 Transformer-5-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Norm  (None, None, 768)    2098688     Transformer-5-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    2098688     Transformer-6-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
      "                                                                 Transformer-6-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Norm  (None, None, 768)    2098688     Transformer-6-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    2098688     Transformer-7-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
      "                                                                 Transformer-7-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Norm  (None, None, 768)    2098688     Transformer-7-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    2098688     Transformer-8-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
      "                                                                 Transformer-8-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Norm  (None, None, 768)    2098688     Transformer-8-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    2098688     Transformer-9-MultiHeadSelfAttent\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
      "                                                                 Transformer-9-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Norm  (None, None, 768)    2098688     Transformer-9-FeedForward-Add[0][\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    2098688     Transformer-10-MultiHeadSelfAtten\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
      "                                                                 Transformer-10-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Norm (None, None, 768)    2098688     Transformer-10-FeedForward-Add[0]\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Attention-UniLM-Mask[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    2098688     Transformer-11-MultiHeadSelfAtten\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
      "                                                                 Transformer-11-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Norm (None, None, 768)    2098688     Transformer-11-FeedForward-Add[0]\n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, None, 768)    590592      Transformer-11-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, None, 768)    2098688     MLM-Dense[0][0]                  \n",
      "                                                                 image_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Bias (BiasAdd)              (None, None, 29190)  29190       Embedding-Token[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Activation (Activation)     (None, None, 29190)  0           MLM-Bias[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cross_entropy_1 (CrossEntropy)  (None, None, 29190)  0           Input-Token[0][0]                \n",
      "                                                                 Input-Segment[0][0]              \n",
      "                                                                 MLM-Activation[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 163,015,942\n",
      "Trainable params: 163,015,942\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist/.local/lib/python3.6/site-packages/keras/engine/training_utils.py:819: UserWarning: Output cross_entropy_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to cross_entropy_1.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    }
   ],
   "source": [
    "output = CrossEntropy(2)(model.inputs[0:2] + model.outputs)\n",
    "\n",
    "model = Model(model.inputs, output)\n",
    "model.compile(optimizer=Adam(1e-5))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoCaption(AutoRegressiveDecoder):\n",
    "    \"\"\"img2seq解码器\n",
    "    \"\"\"\n",
    "    @AutoRegressiveDecoder.set_rtype('probas')\n",
    "    def predict(self, inputs, output_ids, step):\n",
    "        token_ids, segment_ids, image = inputs\n",
    "        token_ids = np.concatenate([token_ids, output_ids], 1)\n",
    "        segment_ids = np.concatenate([segment_ids, np.ones_like(output_ids)], 1)\n",
    "        return model.predict([token_ids, segment_ids, image])[:, -1]\n",
    "\n",
    "    def generate(self, inputs, features, topk=1):\n",
    "        token_ids, segment_ids = tokenizer.encode(inputs, max_length=maxlen)\n",
    "        output_ids = self.beam_search([token_ids, segment_ids, features], topk)  # 基于beam search\n",
    "        return tokenizer.decode(output_ids)\n",
    "\n",
    "\n",
    "autocaption = AutoCaption(\n",
    "    start_id=None,\n",
    "    end_id=tokenizer._token_end_id,\n",
    "    maxlen=maxlen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_show():\n",
    "    samples = [valid_data[i] for i in np.random.choice(len(valid_data), 2, replace=False)]\n",
    "    for D in samples:\n",
    "        features = D['features']\n",
    "        inputs = np.random.choice(D['objects_key_words'])\n",
    "        print(u'image_id:', D['image_id'])\n",
    "        print(u'key_words:', inputs)\n",
    "        print(u'predict:', autocaption.generate(inputs, features))\n",
    "        print(u'references:', D['caption'])\n",
    "        print()\n",
    "    \n",
    "        \n",
    "def caption_eval():\n",
    "        \n",
    "    datasetGTS = {}\n",
    "    datasetRES = {}\n",
    "        \n",
    "    GTS_annotations = []\n",
    "    RES_annotations = []\n",
    "    \n",
    "    samples = [valid_data[i] for i in np.random.choice(len(valid_data), 2, replace=False)]\n",
    "    \n",
    "    imgIds = 0\n",
    "    for _, sample in tqdm(enumerate(samples), desc='Reading data'):\n",
    "        for inputs in sample['objects_key_words']:\n",
    "            res = {}\n",
    "            res[u'image_id'] = imgIds\n",
    "            res[u'caption'] = autocaption.generate(inputs, sample['features'])\n",
    "            RES_annotations.append(res)\n",
    "            \n",
    "            for caption in sample['caption']:\n",
    "                gts = {}\n",
    "                gts[u'image_id'] = imgIds\n",
    "                gts[u'caption'] = caption\n",
    "                GTS_annotations.append(gts)\n",
    "            \n",
    "            imgIds += 1\n",
    "            \n",
    "    imgIds = range(imgIds)\n",
    "        \n",
    "    datasetGTS['annotations'] = GTS_annotations\n",
    "    datasetRES['annotations'] = RES_annotations\n",
    "    \n",
    "    print(u'-Calculating scores ...')\n",
    "    scores = calculate_metrics(imgIds, datasetGTS, datasetRES)\n",
    "    print(scores)\n",
    "    \n",
    "    scores['epoch'] = epoch\n",
    "    scores['loss']  = loss\n",
    "    \n",
    "    if with_key_words:\n",
    "        save_path = 'models/coco2014/base_kw/'\n",
    "    else:\n",
    "        save_path = 'models/coco2014/base/'\n",
    "    \n",
    "    with open(save_path + 'caption_eval.txt', \"a\") as f:\n",
    "        f.write(str(scores) + '\\n')\n",
    "    model.save_weights(save_path + 'model_{}.weights'.format(epoch))\n",
    "    \n",
    "\n",
    "class Evaluate(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.lowest = 1e10\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        just_show()\n",
    "        caption_eval(epoch, logs['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluate()\n",
    "train_generator = data_generator(train_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mist/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 37s 4s/step - loss: 8.5657\n",
      "image_id: COCO_val2014_000000202093.jpg\n",
      "key_words: motorcycle car \n",
      "predict: a a. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "references: ['Several large bulls standing around in a grassy field in front of a farm plantation.', 'A group of cows grazing in the green grass. ', 'A herd of cows on a farm in grassy field.', 'Several cows standing in the grass near a few buildings.', 'A small herd of cows in a large grassy field.']\n",
      "\n",
      "image_id: COCO_val2014_000000278899.jpg\n",
      "key_words: motorcycle roadway vehicle \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: a vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle\n",
      "references: ['a lot of different types of luggage bags near one another', 'A group of purses and backpacks lumped together.', 'A pile of colorful luggage sitting side by side.', 'a large collection of various bags and suitcases', 'There are many suitcases piled up on top of each other. ']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data: 2it [00:13,  6.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Calculating scores ...\n",
      "-tokenization...\n",
      "-setting up scorers...\n",
      "-computing Bleu score...\n",
      "{'testlen': 74, 'reflen': 83, 'guess': [74, 64, 62, 61], 'correct': [3, 1, 0, 0]}\n",
      "ratio: 0.8915662650494992\n",
      "Bleu_1: 0.036\n",
      "Bleu_2: 0.022\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "-computing METEOR score...\n",
      "METEOR: 0.032\n",
      "-computing Rouge score...\n",
      "ROUGE_L: 0.024\n",
      "-computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "-computing SPICE score...\n",
      "SPICE: 0.011\n",
      "-computing WMD score...\n",
      "WMD: 0.022\n",
      "{'Bleu_1': 0.03589797376436835, 'Bleu_2': 0.022286156777206235, 'Bleu_3': 1.9214084279784522e-07, 'Bleu_4': 5.664706459066291e-10, 'METEOR': 0.03189847048799763, 'ROUGE_L': 0.024159561727004307, 'CIDEr': 4.290672868937101e-21, 'SPICE': 0.01111111111111111, 'WMD': 0.02167315840198584}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-648ad790249f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-6052e1c7397f>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mjust_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mcaption_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-6052e1c7397f>\u001b[0m in \u001b[0;36mcaption_eval\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[evaluator]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'caption': 'a woman riding a bike next to a stop sign',\n",
       "  'key_words': 'woman bike sign ',\n",
       "  'features': array([0.26279029, 0.23141171, 0.18918106, ..., 0.30394822, 0.02286127,\n",
       "         0.27747229])},\n",
       " {'caption': 'a woman is riding a bicycle past a stop sign',\n",
       "  'key_words': 'woman bicycle sign ',\n",
       "  'features': array([0.26279029, 0.23141171, 0.18918106, ..., 0.30394822, 0.02286127,\n",
       "         0.27747229])},\n",
       " {'caption': 'a woman her bike past a stop sign',\n",
       "  'key_words': 'woman bike sign ',\n",
       "  'features': array([0.26279029, 0.23141171, 0.18918106, ..., 0.30394822, 0.02286127,\n",
       "         0.27747229])},\n",
       " {'caption': 'a pretty young lady riding a bike by a stop sign',\n",
       "  'key_words': 'lady bike sign ',\n",
       "  'features': array([0.26279029, 0.23141171, 0.18918106, ..., 0.30394822, 0.02286127,\n",
       "         0.27747229])},\n",
       " {'caption': 'a large propeller airplane flying through a cloudy sky',\n",
       "  'key_words': 'airplane sky ',\n",
       "  'features': array([0.34272781, 0.66812372, 0.1074824 , ..., 0.0915942 , 0.22203603,\n",
       "         1.27009857])},\n",
       " {'caption': 'a medium engine plane flying across a sunset sky',\n",
       "  'key_words': 'plane sky ',\n",
       "  'features': array([0.34272781, 0.66812372, 0.1074824 , ..., 0.0915942 , 0.22203603,\n",
       "         1.27009857])},\n",
       " {'caption': 'small white canadian commercial jet in flight at dusk',\n",
       "  'key_words': 'canadian jet flight dusk ',\n",
       "  'features': array([0.34272781, 0.66812372, 0.1074824 , ..., 0.0915942 , 0.22203603,\n",
       "         1.27009857])},\n",
       " {'caption': 'an airplane with a maple leaf on it is flying through the air',\n",
       "  'key_words': 'air airplane leaf ',\n",
       "  'features': array([0.34272781, 0.66812372, 0.1074824 , ..., 0.0915942 , 0.22203603,\n",
       "         1.27009857])},\n",
       " {'caption': 'an adult and a kid with helmets on while on their skis in the snow',\n",
       "  'key_words': 'adult kid helmet while ski snow ',\n",
       "  'features': array([0.19941828, 0.60218906, 0.13827309, ..., 0.03171606, 0.13720578,\n",
       "         0.17419779])},\n",
       " {'caption': 'a person helps a child to ski on a small hill',\n",
       "  'key_words': 'person child hill ',\n",
       "  'features': array([0.19941828, 0.60218906, 0.13827309, ..., 0.03171606, 0.13720578,\n",
       "         0.17419779])},\n",
       " {'caption': 'a couple of people riding skis down a snow covered slope',\n",
       "  'key_words': 'people ski snow slope ',\n",
       "  'features': array([0.19941828, 0.60218906, 0.13827309, ..., 0.03171606, 0.13720578,\n",
       "         0.17419779])},\n",
       " {'caption': 'a woman and child are on skis on the snow',\n",
       "  'key_words': 'woman child ski snow ',\n",
       "  'features': array([0.19941828, 0.60218906, 0.13827309, ..., 0.03171606, 0.13720578,\n",
       "         0.17419779])},\n",
       " {'caption': 'a close up of some bright colorful kites above the beach',\n",
       "  'key_words': 'kite beach ',\n",
       "  'features': array([0.5764513 , 0.58758634, 0.10261671, ..., 0.01022919, 0.91232258,\n",
       "         0.17075068])},\n",
       " {'caption': 'a bunch of kites that are in the air',\n",
       "  'key_words': 'kite ',\n",
       "  'features': array([0.5764513 , 0.58758634, 0.10261671, ..., 0.01022919, 0.91232258,\n",
       "         0.17075068])},\n",
       " {'caption': 'various colorful kites make their ascent into the sky',\n",
       "  'key_words': 'kite ascent sky ',\n",
       "  'features': array([0.5764513 , 0.58758634, 0.10261671, ..., 0.01022919, 0.91232258,\n",
       "         0.17075068])},\n",
       " {'caption': 'a bunch of kites are flying at the beach',\n",
       "  'key_words': 'kite beach ',\n",
       "  'features': array([0.5764513 , 0.58758634, 0.10261671, ..., 0.01022919, 0.91232258,\n",
       "         0.17075068])},\n",
       " {'caption': 'several large kites flying in the air over a beach',\n",
       "  'key_words': 'kite air beach ',\n",
       "  'features': array([0.5764513 , 0.58758634, 0.10261671, ..., 0.01022919, 0.91232258,\n",
       "         0.17075068])},\n",
       " {'caption': 'this is a living room with a small desk area and breakfast bar',\n",
       "  'key_words': 'room area bar ',\n",
       "  'features': array([0.71207523, 0.53143787, 0.04560354, ..., 0.96643907, 0.20679121,\n",
       "         0.03917899])},\n",
       " {'caption': 'living area and kitchen with computer desk bar seating and two couches',\n",
       "  'key_words': 'kitchen seating couch ',\n",
       "  'features': array([0.71207523, 0.53143787, 0.04560354, ..., 0.96643907, 0.20679121,\n",
       "         0.03917899])},\n",
       " {'caption': 'a living room with a desk and a laptop',\n",
       "  'key_words': 'living room desk laptop ',\n",
       "  'features': array([0.71207523, 0.53143787, 0.04560354, ..., 0.96643907, 0.20679121,\n",
       "         0.03917899])},\n",
       " {'caption': 'a kitchen counter that has chairs in front of it',\n",
       "  'key_words': 'kitchen chair ',\n",
       "  'features': array([0.71207523, 0.53143787, 0.04560354, ..., 0.96643907, 0.20679121,\n",
       "         0.03917899])},\n",
       " {'caption': 'a living room and a kitchen all in one room',\n",
       "  'key_words': 'room kitchen ',\n",
       "  'features': array([0.71207523, 0.53143787, 0.04560354, ..., 0.96643907, 0.20679121,\n",
       "         0.03917899])},\n",
       " {'caption': 'a chair with a black teddy bear in it on the sidewalk',\n",
       "  'key_words': 'chair bear sidewalk ',\n",
       "  'features': array([0.32255721, 0.26826251, 0.22835614, ..., 0.09024876, 0.46671689,\n",
       "         0.13468732])},\n",
       " {'caption': 'a armchair with a teddy bear sitting on it on the sidewalk',\n",
       "  'key_words': 'armchair bear sidewalk ',\n",
       "  'features': array([0.32255721, 0.26826251, 0.22835614, ..., 0.09024876, 0.46671689,\n",
       "         0.13468732])},\n",
       " {'caption': 'a black teddy bear sits on love seat on the sidewalk',\n",
       "  'key_words': 'bear seat sidewalk ',\n",
       "  'features': array([0.32255721, 0.26826251, 0.22835614, ..., 0.09024876, 0.46671689,\n",
       "         0.13468732])},\n",
       " {'caption': 'a black teddy bear sitting on a chair out on the sidewalk',\n",
       "  'key_words': 'teddy chair sidewalk ',\n",
       "  'features': array([0.32255721, 0.26826251, 0.22835614, ..., 0.09024876, 0.46671689,\n",
       "         0.13468732])},\n",
       " {'caption': 'an armchair with a stuffed bear on it on the sidewalk',\n",
       "  'key_words': 'armchair bear sidewalk ',\n",
       "  'features': array([0.32255721, 0.26826251, 0.22835614, ..., 0.09024876, 0.46671689,\n",
       "         0.13468732])},\n",
       " {'caption': 'a group of food that is on a table',\n",
       "  'key_words': 'group food table ',\n",
       "  'features': array([1.02975595, 0.4418329 , 0.23361006, ..., 0.10318651, 0.27511293,\n",
       "         0.59118015])},\n",
       " {'caption': 'a cake with tow layer smothered in white frosting',\n",
       "  'key_words': 'cake layer frosting ',\n",
       "  'features': array([1.02975595, 0.4418329 , 0.23361006, ..., 0.10318651, 0.27511293,\n",
       "         0.59118015])},\n",
       " {'caption': 'a cake and bowl of cookies on the table with some jam',\n",
       "  'key_words': 'cake bowl cookie table jam ',\n",
       "  'features': array([1.02975595, 0.4418329 , 0.23361006, ..., 0.10318651, 0.27511293,\n",
       "         0.59118015])},\n",
       " {'caption': 'desserts and jams are arranged on the top of a counter',\n",
       "  'key_words': 'dessert jam top counter ',\n",
       "  'features': array([1.02975595, 0.4418329 , 0.23361006, ..., 0.10318651, 0.27511293,\n",
       "         0.59118015])},\n",
       " {'caption': 'an iced cake two jars of jelly and a container of cookies',\n",
       "  'key_words': 'cake jar jelly container cookie ',\n",
       "  'features': array([1.02975595, 0.4418329 , 0.23361006, ..., 0.10318651, 0.27511293,\n",
       "         0.59118015])},\n",
       " {'caption': 'an apple between two pomegranates siting on a table covered by a white table cloth',\n",
       "  'key_words': 'apple pomegranate table cloth ',\n",
       "  'features': array([0.14673656, 0.44545248, 0.01987111, ..., 0.08354528, 0.47197866,\n",
       "         0.08105021])},\n",
       " {'caption': 'two fruits and an apple next to each other on a counter',\n",
       "  'key_words': 'fruit apple counter ',\n",
       "  'features': array([0.14673656, 0.44545248, 0.01987111, ..., 0.08354528, 0.47197866,\n",
       "         0.08105021])},\n",
       " {'caption': 'two pomegranates and an apple sit on the table',\n",
       "  'key_words': 'pomegranate apple table ',\n",
       "  'features': array([0.14673656, 0.44545248, 0.01987111, ..., 0.08354528, 0.47197866,\n",
       "         0.08105021])},\n",
       " {'caption': 'a green apple is between two large red fruit',\n",
       "  'key_words': 'apple fruit ',\n",
       "  'features': array([0.14673656, 0.44545248, 0.01987111, ..., 0.08354528, 0.47197866,\n",
       "         0.08105021])},\n",
       " {'caption': 'a table topped with fruits and other clutter',\n",
       "  'key_words': 'table fruit clutter ',\n",
       "  'features': array([0.14673656, 0.44545248, 0.01987111, ..., 0.08354528, 0.47197866,\n",
       "         0.08105021])},\n",
       " {'caption': 'a snowboarder in a green jacket sitting in the snow',\n",
       "  'key_words': 'snowboarder snow jacket ',\n",
       "  'features': array([0.31169048, 0.29700872, 0.2961629 , ..., 0.10458277, 0.377819  ,\n",
       "         0.03778153])},\n",
       " {'caption': 'a person lying on the ground on a snow board',\n",
       "  'key_words': 'person ground board ',\n",
       "  'features': array([0.31169048, 0.29700872, 0.2961629 , ..., 0.10458277, 0.377819  ,\n",
       "         0.03778153])},\n",
       " {'caption': 'a young man riding a snowboard on a snow covered slope',\n",
       "  'key_words': 'man snowboard snow slope ',\n",
       "  'features': array([0.31169048, 0.29700872, 0.2961629 , ..., 0.10458277, 0.377819  ,\n",
       "         0.03778153])},\n",
       " {'caption': 'there are horses and many sheep on a farm',\n",
       "  'key_words': 'horse sheep farm ',\n",
       "  'features': array([0.01407687, 0.34650466, 0.05965273, ..., 0.62827975, 0.10407106,\n",
       "         0.42539164])},\n",
       " {'caption': 'a man on a horse and some sheep and other horses',\n",
       "  'key_words': 'man horse sheep ',\n",
       "  'features': array([0.01407687, 0.34650466, 0.05965273, ..., 0.62827975, 0.10407106,\n",
       "         0.42539164])},\n",
       " {'caption': 'a farmer on a horse rounding up some sheep',\n",
       "  'key_words': 'farmer horse sheep ',\n",
       "  'features': array([0.01407687, 0.34650466, 0.05965273, ..., 0.62827975, 0.10407106,\n",
       "         0.42539164])}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 'COCO_val2014_000000178078.jpg',\n",
       "  'features': array([0.02026431, 0.36134467, 0.26312259, ..., 0.1018953 , 0.32963011,\n",
       "         0.32357308]),\n",
       "  'caption': ['a line of cars with a motorcycle in front',\n",
       "   'A bike is posed in front of an old car.',\n",
       "   'A red motorcycle parked in front of a parked car.',\n",
       "   'Motorcycle parked on roadway with other vehicles nearby.',\n",
       "   'The motorcycle is parallel parked sideways in front of cars.'],\n",
       "  'objects_key_words': ['bike car ',\n",
       "   'motorcycle car ',\n",
       "   'motorcycle roadway vehicle ',\n",
       "   'motorcycle car ']},\n",
       " {'image_id': 'COCO_val2014_000000121572.jpg',\n",
       "  'features': array([0.12468677, 0.40851697, 0.19564483, ..., 1.2679621 , 0.00757444,\n",
       "         0.13152997]),\n",
       "  'caption': ['a couple of buses that are lined up by some buildings',\n",
       "   'Some busses are parked along the city curb.',\n",
       "   'Buses parked along a curb beside old buildings ',\n",
       "   'A red double decker bus is in front of a white bus on the side of a road. ',\n",
       "   'there are many double decker busses along this street',\n",
       "   'A couple of red double decker buses sandwiching a small white bus.'],\n",
       "  'objects_key_words': ['bus building ',\n",
       "   'bus curb ',\n",
       "   'bus curb building ',\n",
       "   'bus side road ',\n",
       "   'bus street ',\n",
       "   'bus ']},\n",
       " {'image_id': 'COCO_val2014_000000002315.jpg',\n",
       "  'features': array([0.32785866, 0.67275894, 0.14322917, ..., 0.22412814, 0.13452926,\n",
       "         0.10852578]),\n",
       "  'caption': ['A herd of elephants in the wild near a river.',\n",
       "   'Several elephants walking on dirt and grass near body of water.',\n",
       "   'A herd of elephants standing next to a river.',\n",
       "   'Elephants in the water and on the banks under palm trees.',\n",
       "   'Elephants are standing in and near a water source.'],\n",
       "  'objects_key_words': ['elephant dirt grass body water ',\n",
       "   'herd elephant river ',\n",
       "   'elephant water bank tree ',\n",
       "   'elephant source ']},\n",
       " {'image_id': 'COCO_val2014_000000502644.jpg',\n",
       "  'features': array([0.36753947, 0.18247451, 0.06485816, ..., 0.20665088, 0.17493856,\n",
       "         0.11241766]),\n",
       "  'caption': ['A woman sitting on a toilet with a mask on. ',\n",
       "   'A half dressed lady on a toilet wearing a mask.',\n",
       "   'Woman in dark costume with helmet prop sitting on toilet.',\n",
       "   'A woman in a mask on a toilet.',\n",
       "   'A woman wearing a Darth Vader masks setting on a toilet.'],\n",
       "  'objects_key_words': ['woman toilet mask ',\n",
       "   'half lady toilet mask ',\n",
       "   'woman mask toilet ']},\n",
       " {'image_id': 'COCO_val2014_000000353551.jpg',\n",
       "  'features': array([0.58720571, 0.44637352, 0.        , ..., 0.28651625, 0.03463382,\n",
       "         0.28772604]),\n",
       "  'caption': ['A large passenger jet flying over the top of a forest.',\n",
       "   'A large commercial airplane is flying pretty low.',\n",
       "   'A plane is flying in the sky over trees.',\n",
       "   'Airplane flying low over the treeline and field beyond.',\n",
       "   'A large airplane flies in blue skies over some pretty trees.'],\n",
       "  'objects_key_words': ['jet top forest ',\n",
       "   'airplane ',\n",
       "   'plane sky tree ',\n",
       "   'airplane treeline field ',\n",
       "   'airplane sky tree ']},\n",
       " {'image_id': 'COCO_val2014_000000180510.jpg',\n",
       "  'features': array([0.28100353, 0.10010953, 0.0608261 , ..., 0.00125964, 0.07868433,\n",
       "         0.40908551]),\n",
       "  'caption': ['a train on a train track with a sky in the background',\n",
       "   'A large yellow and black train traveling through rural countryside.',\n",
       "   'A yellow and black train traveling beneath a blue sky.',\n",
       "   'A man is standing on the top of a yellow and black train.',\n",
       "   'A yellow and black train speeding along the rails.'],\n",
       "  'objects_key_words': ['train track sky background ',\n",
       "   'train countryside ',\n",
       "   'train sky ',\n",
       "   'man top train ',\n",
       "   'rail train speeding ']},\n",
       " {'image_id': 'COCO_val2014_000000218855.jpg',\n",
       "  'features': array([0.49590519, 0.74800545, 0.23737511, ..., 0.18882726, 0.61485851,\n",
       "         0.50452471]),\n",
       "  'caption': ['A bunch of people are sitting around while a guy plays a video game\\n',\n",
       "   'A group of people playing a game with remote controllers.',\n",
       "   'a loving family watching others as they play video game',\n",
       "   'A group of people sitting around a room holding game controllers.',\n",
       "   'A man sits in a chair as he plays a video game with a wii mote'],\n",
       "  'objects_key_words': ['people guy game ',\n",
       "   'group people game controller ',\n",
       "   'group people room controller ']},\n",
       " {'image_id': 'COCO_val2014_000000190738.jpg',\n",
       "  'features': array([0.21105027, 0.2464729 , 0.5524525 , ..., 0.10572548, 0.04382778,\n",
       "         0.59181523]),\n",
       "  'caption': ['A baseball player standing on  home plate holding a bat.',\n",
       "   'The batter prepared to swing at the oncoming pitch.',\n",
       "   'The batter is getting ready to hit the ball.',\n",
       "   'A person holding a bat ready to swing at a baseball with a catcher and umpire behind.',\n",
       "   'Baseball players in uniform playing the game of baseball'],\n",
       "  'objects_key_words': ['standing plate bat ',\n",
       "   'batter pitch ',\n",
       "   'batter ball ',\n",
       "   'person bat baseball catcher ',\n",
       "   'baseball player playing game ']},\n",
       " {'image_id': 'COCO_val2014_000000007333.jpg',\n",
       "  'features': array([0.71134377, 0.32986125, 0.24903265, ..., 0.01791648, 0.06537439,\n",
       "         0.38687664]),\n",
       "  'caption': ['A young man riding a skateboard across leaf covered ground.',\n",
       "   'A little boy that is standing on a skateboard.',\n",
       "   'A boy riding a skateboard down a sidewalk.',\n",
       "   'A young boy is having fun riding his skateboard in the park. ',\n",
       "   'A boy in black shirt and yellow pants riding skateboard'],\n",
       "  'objects_key_words': ['man skateboard leaf ground ',\n",
       "   'boy skateboard ',\n",
       "   'boy skateboard sidewalk ',\n",
       "   'boy shirt riding ']},\n",
       " {'image_id': 'COCO_val2014_000000194832.jpg',\n",
       "  'features': array([0.12308149, 0.12880728, 0.04975556, ..., 0.21499765, 0.46818101,\n",
       "         0.        ]),\n",
       "  'caption': ['A television screen is displayed in an empty bus.',\n",
       "   'A vacant bus has seats facing in multiple directions.',\n",
       "   'The inside of a commuter city bus with palide seats',\n",
       "   'An empty bus with brown cloth covered seats.',\n",
       "   'An empty bus has tartan seats, and a wooden floor.'],\n",
       "  'objects_key_words': ['screen bus ',\n",
       "   'bus seat direction ',\n",
       "   'inside bus seat ',\n",
       "   'bus cloth seat ',\n",
       "   'bus seat floor ']}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data: 2it [00:00, 2007.32it/s]\n"
     ]
    }
   ],
   "source": [
    "GTS_annotations, RES_annotations = caption_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 0,\n",
       "  'caption': 'two cats in an office space looking at the camera'},\n",
       " {'image_id': 0,\n",
       "  'caption': 'two cats sitting together on a desk next to a keyboard'},\n",
       " {'image_id': 0, 'caption': 'two cats laying on a desk by a keyboard'},\n",
       " {'image_id': 0, 'caption': 'two cats sitting on a desk behind a keyboard'},\n",
       " {'image_id': 0,\n",
       "  'caption': 'two cats lying on desk facing camera with a keyboard in foreground'},\n",
       " {'image_id': 1,\n",
       "  'caption': 'two cats in an office space looking at the camera'},\n",
       " {'image_id': 1,\n",
       "  'caption': 'two cats sitting together on a desk next to a keyboard'},\n",
       " {'image_id': 1, 'caption': 'two cats laying on a desk by a keyboard'},\n",
       " {'image_id': 1, 'caption': 'two cats sitting on a desk behind a keyboard'},\n",
       " {'image_id': 1,\n",
       "  'caption': 'two cats lying on desk facing camera with a keyboard in foreground'},\n",
       " {'image_id': 2,\n",
       "  'caption': 'two cats in an office space looking at the camera'},\n",
       " {'image_id': 2,\n",
       "  'caption': 'two cats sitting together on a desk next to a keyboard'},\n",
       " {'image_id': 2, 'caption': 'two cats laying on a desk by a keyboard'},\n",
       " {'image_id': 2, 'caption': 'two cats sitting on a desk behind a keyboard'},\n",
       " {'image_id': 2,\n",
       "  'caption': 'two cats lying on desk facing camera with a keyboard in foreground'},\n",
       " {'image_id': 3,\n",
       "  'caption': 'two cats in an office space looking at the camera'},\n",
       " {'image_id': 3,\n",
       "  'caption': 'two cats sitting together on a desk next to a keyboard'},\n",
       " {'image_id': 3, 'caption': 'two cats laying on a desk by a keyboard'},\n",
       " {'image_id': 3, 'caption': 'two cats sitting on a desk behind a keyboard'},\n",
       " {'image_id': 3,\n",
       "  'caption': 'two cats lying on desk facing camera with a keyboard in foreground'},\n",
       " {'image_id': 4,\n",
       "  'caption': 'two cats in an office space looking at the camera'},\n",
       " {'image_id': 4,\n",
       "  'caption': 'two cats sitting together on a desk next to a keyboard'},\n",
       " {'image_id': 4, 'caption': 'two cats laying on a desk by a keyboard'},\n",
       " {'image_id': 4, 'caption': 'two cats sitting on a desk behind a keyboard'},\n",
       " {'image_id': 4,\n",
       "  'caption': 'two cats lying on desk facing camera with a keyboard in foreground'},\n",
       " {'image_id': 5, 'caption': 'a shirtless man playing tennis on a blue court'},\n",
       " {'image_id': 5,\n",
       "  'caption': 'an image of a shirtless man hitting tennis racket'},\n",
       " {'image_id': 5,\n",
       "  'caption': 'a man is standing on a court with a tennis racket'},\n",
       " {'image_id': 5, 'caption': 'a man on a court swinging a tennis racket'},\n",
       " {'image_id': 6, 'caption': 'a shirtless man playing tennis on a blue court'},\n",
       " {'image_id': 6,\n",
       "  'caption': 'an image of a shirtless man hitting tennis racket'},\n",
       " {'image_id': 6,\n",
       "  'caption': 'a man is standing on a court with a tennis racket'},\n",
       " {'image_id': 6, 'caption': 'a man on a court swinging a tennis racket'},\n",
       " {'image_id': 7, 'caption': 'a shirtless man playing tennis on a blue court'},\n",
       " {'image_id': 7,\n",
       "  'caption': 'an image of a shirtless man hitting tennis racket'},\n",
       " {'image_id': 7,\n",
       "  'caption': 'a man is standing on a court with a tennis racket'},\n",
       " {'image_id': 7, 'caption': 'a man on a court swinging a tennis racket'},\n",
       " {'image_id': 8, 'caption': 'a shirtless man playing tennis on a blue court'},\n",
       " {'image_id': 8,\n",
       "  'caption': 'an image of a shirtless man hitting tennis racket'},\n",
       " {'image_id': 8,\n",
       "  'caption': 'a man is standing on a court with a tennis racket'},\n",
       " {'image_id': 8, 'caption': 'a man on a court swinging a tennis racket'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GTS_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 0, 'caption': ''},\n",
       " {'image_id': 1, 'caption': ''},\n",
       " {'image_id': 2, 'caption': ''},\n",
       " {'image_id': 3, 'caption': ''},\n",
       " {'image_id': 4, 'caption': ''},\n",
       " {'image_id': 5, 'caption': ''},\n",
       " {'image_id': 6, 'caption': ''},\n",
       " {'image_id': 7, 'caption': ''},\n",
       " {'image_id': 8, 'caption': ''}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RES_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347074"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40263"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
